{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"C:/Users/SHRADDHA RUHELA/OneDrive/Desktop/KNOWLEDGE_GRAPH\")  # Set it to the project root\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "## Input data directory\n",
    "data_dir = \"OrfPathHealth\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =  0\n"
     ]
    }
   ],
   "source": [
    "## Dir Loader\n",
    "documents = PyPDFDirectoryLoader(inputdirectory).load()\n",
    "## File Loader\n",
    "# documents = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\").load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of all the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers.df_helpers import documents2Dataframe\n",
    "df = documents2Dataframe(pages)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function uses the helpers/prompt function to extract concepts from text\n",
    "from helpers.df_helpers import df2ConceptsList\n",
    "from helpers.df_helpers import concepts2Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m concepts_list \u001b[38;5;241m=\u001b[39m \u001b[43mdf2ConceptsList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\KNOWLEDGE_GRAPH\\helpers\\df_helpers.py:36\u001b[0m, in \u001b[0;36mdf2ConceptsList\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     33\u001b[0m results \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m## Flatten the list of lists to one single list of entities.\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m concept_list \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concept_list\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "concepts_list = df2ConceptsList(df[10:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>importance</th>\n",
       "      <th>category</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mental Health</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "      <td>83d4d0367bb0467e811782a4ada3bbb9</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health Equity</td>\n",
       "      <td>4</td>\n",
       "      <td>concept</td>\n",
       "      <td>83d4d0367bb0467e811782a4ada3bbb9</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World Health Organization (WHO)</td>\n",
       "      <td>3</td>\n",
       "      <td>organisation</td>\n",
       "      <td>83d4d0367bb0467e811782a4ada3bbb9</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Nations (UN)</td>\n",
       "      <td>3</td>\n",
       "      <td>organisation</td>\n",
       "      <td>83d4d0367bb0467e811782a4ada3bbb9</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sustainable Development Goals (SDGs)</td>\n",
       "      <td>4</td>\n",
       "      <td>document</td>\n",
       "      <td>83d4d0367bb0467e811782a4ada3bbb9</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 entity  importance      category  \\\n",
       "0                         Mental Health           5       concept   \n",
       "1                         Health Equity           4       concept   \n",
       "2       World Health Organization (WHO)           3  organisation   \n",
       "3                   United Nations (UN)           3  organisation   \n",
       "4  Sustainable Development Goals (SDGs)           4      document   \n",
       "\n",
       "                           chunk_id     type  \n",
       "0  83d4d0367bb0467e811782a4ada3bbb9  concept  \n",
       "1  83d4d0367bb0467e811782a4ada3bbb9  concept  \n",
       "2  83d4d0367bb0467e811782a4ada3bbb9  concept  \n",
       "3  83d4d0367bb0467e811782a4ada3bbb9  concept  \n",
       "4  83d4d0367bb0467e811782a4ada3bbb9  concept  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfne = concepts2Df(concepts_list)\n",
    "dfne.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write CSV to an output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the dataframes are written in the csv format so we dont have to calculate them again. \n",
    "\n",
    "        dfne = dataframe of names entities\n",
    "\n",
    "        df = dataframe of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outputdirectory):\n",
    "   os.makedirs(outputdirectory)\n",
    "   \n",
    "dfne.to_csv(outputdirectory/\"concepts.csv\", sep=\"|\", index=False)\n",
    "df.to_csv(outputdirectory/\"chunks.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities from Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not using this right now**\n",
    "\n",
    "Extracting named entities our of concepts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7446a937e7ce455ba50ba4018e5c7895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/934 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRADDHA RUHELA\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SHRADDHA RUHELA\\.cache\\huggingface\\hub\\models--2rtl3--mn-xlm-roberta-base-named-entity. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02643cc71544d359a811292fcb951b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615e71bf7bca477fbdcae2e4bfa01fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371761f217f54d6c97b3a72a7db756b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab5946db65f4a2cae27db9fe9fda54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d08f057b64484994a778d7574d3dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643ae878e84e4377a14fa7383aec3d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"token-classification\", model=\"2rtl3/mn-xlm-roberta-base-named-entity\", aggregation_strategy=\"simple\")\n",
    "# ner = pipeline(\"token-classification\", model=\"dslim/bert-large-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "def row2NamedEntities(row):\n",
    "    ner_results = ner(row['entity'])\n",
    "    metadata = {'chunk_id': row['chunk_id'], 'type': 'entity'}\n",
    "    entities = []\n",
    "    for result in ner_results:\n",
    "        entities = entities + [{'entity': result['word'], 'catetory': result['entity_group'], **metadata}]\n",
    "        \n",
    "    return entities\n",
    "\n",
    "\n",
    "\n",
    "def dfText2DfNE(dataframe: pd.DataFrame):\n",
    "    ## Takes a dataframe from the parsed data and returns dataframe with named entities. \n",
    "    ## The input dataframe must have a entity and a chunk_id column. \n",
    "\n",
    "    ## 1. Calculate named entities for each row of the dataframe. \n",
    "    results = dataframe.apply(row2NamedEntities, axis=1).reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities. \n",
    "    entities_list = np.concatenate(results).ravel().tolist()\n",
    "\n",
    "    ## Remove all NaN entities\n",
    "    entities_dataframe = pd.DataFrame(entities_list).replace(' ', np.nan)\n",
    "    entities_dataframe = entities_dataframe.dropna(subset=['entity'])\n",
    "\n",
    "    ## Count the number of occurances per chunk id\n",
    "    # entities_dataframe = entities_dataframe.groupby(['entity', 'category', 'chunk_id']).size().reset_index(name='count')\n",
    "\n",
    "    return entities_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>catetory</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vid</td>\n",
       "      <td>PER</td>\n",
       "      <td>c70a9f10efce49bd98ff27d64a35b5a0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fhir</td>\n",
       "      <td>PER</td>\n",
       "      <td>d9f17a05951440e5891234fbd510f819</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world</td>\n",
       "      <td>ORG</td>\n",
       "      <td>b44d09e785ae4fc89b5bb70810e7bd99</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>organization</td>\n",
       "      <td>ORG</td>\n",
       "      <td>b44d09e785ae4fc89b5bb70810e7bd99</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world</td>\n",
       "      <td>ORG</td>\n",
       "      <td>b44d09e785ae4fc89b5bb70810e7bd99</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>the usa</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2ccc33d78d5648019b9070572c8ea5d0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>australia</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2ccc33d78d5648019b9070572c8ea5d0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>netherlands</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2ccc33d78d5648019b9070572c8ea5d0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>nia</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2ccc33d78d5648019b9070572c8ea5d0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>singapore</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2ccc33d78d5648019b9070572c8ea5d0</td>\n",
       "      <td>entity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          entity catetory                          chunk_id    type\n",
       "0            vid      PER  c70a9f10efce49bd98ff27d64a35b5a0  entity\n",
       "1           fhir      PER  d9f17a05951440e5891234fbd510f819  entity\n",
       "2          world      ORG  b44d09e785ae4fc89b5bb70810e7bd99  entity\n",
       "3   organization      ORG  b44d09e785ae4fc89b5bb70810e7bd99  entity\n",
       "4          world      ORG  b44d09e785ae4fc89b5bb70810e7bd99  entity\n",
       "..           ...      ...                               ...     ...\n",
       "61       the usa      LOC  2ccc33d78d5648019b9070572c8ea5d0  entity\n",
       "62     australia      LOC  2ccc33d78d5648019b9070572c8ea5d0  entity\n",
       "63   netherlands      LOC  2ccc33d78d5648019b9070572c8ea5d0  entity\n",
       "64           nia      LOC  2ccc33d78d5648019b9070572c8ea5d0  entity\n",
       "65     singapore      LOC  2ccc33d78d5648019b9070572c8ea5d0  entity\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframe_dir = 'OrfPathHealth'  \n",
    "df_concepts = pd.read_csv(f\"C:/Users/SHRADDHA RUHELA/OneDrive/Desktop/knowledge_graph/data_output/MediumArticles/concepts.csv\", sep=\"|\")\n",
    "\n",
    "\n",
    "dfc_split = dfText2DfNE(df_concepts)\n",
    "dfc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
